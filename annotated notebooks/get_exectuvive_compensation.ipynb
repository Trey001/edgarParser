{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get executive compensation ##\n",
    "\n",
    "This notebook contains a few functions to get the executive compensation from DEF14A fillings. Executive compensation is reported in the Summary Compensation Table. The function *get_executive_compensation()* takes a link filling as argument and returns a data frame with the compensation information.  \n",
    "\n",
    "Although all tables look very similar, there are a lot of variability underhood (e.g. header spread across multiple lines, alignment problems between names and year). Thus, many of functions seek to clean the table (see outline below for details) \n",
    "\n",
    "* get_executive_compensation(link)\n",
    "  * -get_table(link) # identify the compensation table and return a dataframe  \n",
    "  * -fix_columns(data) # identify header, normalize basic columns names  \n",
    "  * -fix_duplicated_columns(data) # drop duplicated columns\n",
    "  * -fix_executives_names(data) # get executives names and roles, separate rows if needed\n",
    "  * -get_firm_identification(link) # gather firm identification\n",
    "  * return - dataframe\n",
    "\n",
    "**Caveats:**  \n",
    "At this time, there is no function to normalize all columns name or table values.  \n",
    "Function was developd to work with fillings submitted after 2004, but it may fail. For me, it worked sucessfully in 60% of fillings (sample of 80k fillings).   \n",
    "The get_executive_compensation() is a parser. You need to feed a SEC link into it. There are many python and r packages to get a direct link to the fillings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import html5lib\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_executive_compensation(link):\n",
    "    data = get_table(link)\n",
    "    data = data.replace(\"\\(\\$\\)\", \"\", regex = True)\n",
    "    data = data.replace(\"^\\s*\\$\\s*$\", np.nan, regex = True)\n",
    "    data = data.replace(\"\\([\\d\\#\\*\\w]*\\)\", \"\", regex = True)\n",
    "    data = data.replace(\"\\*\", \"\", regex = True)\n",
    "    data = data.replace(\"\\$\", \"\", regex = True)\n",
    "    data = data.replace(\"^\\x97+$\", np.nan, regex = True)\n",
    "    data = data.replace(\"\\x92\", \"'\", regex = True)\n",
    "    data = data.replace(\"^\\s*$\", np.nan, regex = True)\n",
    "    data = data.dropna(how = \"all\", axis = 1)\n",
    "    data = fix_columns(data)\n",
    "    data = data.dropna(how = \"all\", axis = 1)\n",
    "    data = fix_duplicated_columns(data)\n",
    "    data = fix_executives_names(data)\n",
    "    data[\"cik\"] = get_firm_identification(link)[0]\n",
    "    data[\"conm\"] = get_firm_identification(link)[1]\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table(link):\n",
    "    text = requests.get(link)\n",
    "    text_find = \"Name\\s+and\\s+Principal\\s+Position|Name\\s+and\\s+Principal|Principal\\s+Position|Name\\s+and\\s+Position|Name\\s+\\&|Name\\/Position\"\n",
    "    page = bs(text.content, \"lxml\")\n",
    "    element = page.find_all(text = re.compile(text_find, re.I))\n",
    "    if len(element) > 1:\n",
    "        size = 0\n",
    "        for i in range(0, len(element)):\n",
    "            try:\n",
    "                table = element[i].findParent(\"table\")\n",
    "                dt = pd.read_html(table.prettify(), flavor = \"html5lib\") \n",
    "                dt = dt[0]\n",
    "                if any(salary.search(str(i)) for i in dt.columns) == True:\n",
    "                    data = dt\n",
    "                else:          \n",
    "                    for cols in dt.columns:\n",
    "                        for i in dt[cols]:\n",
    "                            if salary.search(str(i)) is not None:\n",
    "                                data = dt\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "    else:    \n",
    "        table = element[0].findParent(\"table\")\n",
    "        data = pd.read_html(table.prettify(), flavor = \"html5lib\")\n",
    "        data = data[0]\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_firm_identification(text):\n",
    "    text = requests.get(link)\n",
    "    page = bs(text.content, \"lxml\")\n",
    "    company_cik = re.compile(\"(CENTRAL INDEX KEY:)([\\s\\d]+)\")\n",
    "    company_name = re.compile(\"(COMPANY CONFORMED NAME:)([\\s\\d\\w]+)\")\n",
    "    cik = company_cik.search(page.get_text()).group(2).strip()\n",
    "    company_name = company_name.search(page.get_text()).group(2).strip()\n",
    "    company_name = re.sub(\"CENTRAL INDEX KEY\", \"\", company_name).strip()\n",
    "    return([cik, company_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_columns(data):\n",
    "    name = re.compile(\"Name\")\n",
    "    if any(name.search(str(i)) is not None for i in data.columns) == True:\n",
    "        dt = fix_header(data)\n",
    "    else:\n",
    "        header = get_header(data)\n",
    "        col_names = get_col_names(data, header)\n",
    "        data = data.drop(data.index[:(header+1)])\n",
    "        data.columns = col_names\n",
    "        dt = data\n",
    "    dt = fix_double_spaces(dt)\n",
    "    return(dt)\n",
    "\n",
    "def get_header(df):\n",
    "    df[df.columns] = df.apply(lambda x: x.str.strip())\n",
    "    last_row = len(df.index) -1\n",
    "    colnames = df.columns\n",
    "    if all(df[colnames[0]].loc[last_row] == i for i in df[colnames[1:]].loc[last_row]) == True:\n",
    "        df = df.drop(df.index[last_row])\n",
    "        df = df.copy()\n",
    "    else:\n",
    "        df = df\n",
    "    if len(df.loc[(df[0].str.contains(\"Position\", case = False)) & (pd.isna(df[0]) == False)].index.values) > 1: \n",
    "        n = len(df.loc[(df[0].str.contains(\"Position\", case = False)) & (pd.isna(df[0]) == False)].index.values) - 1\n",
    "        header = df.loc[(df[0].str.contains(\"Position\", case = False)) & (pd.isna(df[0]) == False)].index.values[n]\n",
    "    else:\n",
    "        header = df.loc[(df[0].str.contains(\"Position\", case = False)) & (pd.isna(df[0]) == False)].index.values[0]\n",
    "    return(header)\n",
    "\n",
    "def fix_header(df):\n",
    "    try:\n",
    "        x = len(df.columns.levels)\n",
    "        counter = 0\n",
    "    except:\n",
    "        counter = 1\n",
    "    if counter == 0:\n",
    "        columns_name = []\n",
    "        for i in df.columns:\n",
    "            i = i[(len(df.columns.levels)-1)]\n",
    "            i = re.sub(\"Annual\\s*Compensation\", \"\", i)\n",
    "            i = re.sub(\"Long[\\-]*Term\\s*Compensation\\s*Awards*\", \"\", i)\n",
    "            i = re.sub(\"Fiscal\\s+Period\", \"Year\", i)\n",
    "            i = re.sub(\"Fiscal\\s+Year\\s+Ended\", \"Year\", i)\n",
    "            i = re.sub(\"Fiscal\", \"\", i)\n",
    "            i = re.sub(\"Years Covered\", \"Year\", i)\n",
    "            i = re.sub(\"Years\", \"Year\", i)\n",
    "            i = re.sub(\"Year Year\", \"Year\", i)\n",
    "            i = re.sub(\"Year\\s+Year\", \"Year\", i)\n",
    "            i = re.sub(\"SUMMARY\\s*COMPENSATION\\s*TABLE\", \"\", i)\n",
    "            i = re.sub(\"Name.+\", \"Name and Principal Position\", i, re.I) \n",
    "            i = re.sub(\"Summary Compensation Table\", \"\", i)\n",
    "            i = re.sub(\"Adjusted\\s+\", \"\", i)\n",
    "            i = re.sub(\"\\([\\d\\$\\#\\w]+\\)\", \"\", i)\n",
    "            i = re.sub(\"\\d\", \"\", i)\n",
    "            i = re.sub(\"\\.\", \"\", i)\n",
    "            columns_name.append(i)\n",
    "        df.columns = columns_name\n",
    "    else:\n",
    "        columns_name = []\n",
    "        for i in df.columns:\n",
    "            i = re.sub(\"Annual\\s*Compensation\", \"\", i)\n",
    "            i = re.sub(\"Long[\\-]*Term\\s*Compensation\\s*Awards*\", \"\", i)\n",
    "            i = re.sub(\"Fiscal\\s+Period\", \"Year\", i)\n",
    "            i = re.sub(\"Fiscal\\s+Year\\s+Ended\", \"Year\", i)\n",
    "            i = re.sub(\"Fiscal\", \"\", i)\n",
    "            i = re.sub(\"Years Covered\", \"Year\", i)\n",
    "            i = re.sub(\"Years\", \"Year\", i)\n",
    "            i = re.sub(\"Year Year\", \"Year\", i)\n",
    "            i = re.sub(\"Year\\s+Year\", \"Year\", i)\n",
    "            i = re.sub(\"SUMMARY\\s*COMPENSATION\\s*TABLE\", \"\", i)\n",
    "            i = re.sub(\"Summary Compensation Table\", \"\", i)\n",
    "            i = re.sub(\"Name.+\", \"Name and Principal Position\", i, re.I) \n",
    "            i = re.sub(\"Adjusted\\s+\", \"\", i)\n",
    "            i = re.sub(\"\\([\\d\\$\\#\\w]+\\)\", \"\", i)\n",
    "            i = re.sub(\"\\d\", \"\", i)\n",
    "            i = re.sub(\"\\.\", \"\", i)\n",
    "            columns_name.append(i.strip())\n",
    "        df.columns = columns_name\n",
    "           \n",
    "    return(df)\n",
    "\n",
    "def get_col_names(df, value):\n",
    "    col_names_data = df[:(value+1)]\n",
    "    col_names_data = col_names_data.fillna(\"\")\n",
    "    col_list = list()\n",
    "    col_list_final = list()\n",
    "    for col in col_names_data.columns:\n",
    "        name = \"\"\n",
    "        for i in col_names_data[col]:\n",
    "            name = name + \" \" + i\n",
    "        name = name.strip()    \n",
    "        col_list.append(name)\n",
    "    for i in col_list:\n",
    "        i = re.sub(\"Annual\\s*Compensation\", \"\", i)\n",
    "        i = re.sub(\"Long[\\-]*Term\\s*Compensation\\s*Awards*\", \"\", i)\n",
    "        i = re.sub(\"Fiscal\\s+Year\\s+Ended\", \"Year\", i)\n",
    "        i = re.sub(\"Fiscal\\s+Period\", \"Year\", i)\n",
    "        i = re.sub(\"Fiscal\", \"\", i)\n",
    "        i = re.sub(\"Years Covered\", \"Year\", i)\n",
    "        i = re.sub(\"Years\", \"Year\", i)\n",
    "        i = re.sub(\"Year Year\", \"Year\", i)\n",
    "        i = re.sub(\"Year\\s+Year\", \"Year\", i)\n",
    "        i = re.sub(\"SUMMARY\\s*COMPENSATION\\s*TABLE\", \"\", i)\n",
    "        i = re.sub(\"Summary Compensation Table\", \"\", i)\n",
    "        i = re.sub(\"Name.+\", \"Name and Principal Position\", i, re.I) \n",
    "        i = re.sub(\"Adjusted\\s+\", \"\", i)\n",
    "        i = re.sub(\"\\([\\d\\$\\#\\w]+\\)\", \"\", i)\n",
    "        i = re.sub(\"\\d\", \"\", i)\n",
    "        i = re.sub(\"\\.\", \"\", i)\n",
    "        col_list_final.append(i.strip())\n",
    "    return(col_list_final)\n",
    "def fix_double_spaces(data):\n",
    "    col_names = list()\n",
    "    for i in data.columns:\n",
    "        i = re.sub(\"\\s{1,10}\", \" \", i)\n",
    "        col_names.append(i.strip())\n",
    "        \n",
    "    data.columns = col_names\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_duplicated_columns(data):\n",
    "    if \"\" in data.columns: \n",
    "        data = data.drop(\"\", axis = 1)\n",
    "    identify_dup = list()\n",
    "    col_names = data.columns\n",
    "    problem = 0\n",
    "    for i in col_names:\n",
    "        if i in identify_dup:\n",
    "            i = i + \"_dup\"\n",
    "            identify_dup.append(i)\n",
    "            problem = 1\n",
    "        else:\n",
    "            identify_dup.append(i)\n",
    "    if problem == 1:\n",
    "        data.columns = identify_dup\n",
    "        cols_to_drop = list()\n",
    "        for i in identify_dup:\n",
    "            na = data[i].isna().sum()\n",
    "            name = i\n",
    "            final_name = re.sub(\"_dup\", \"\", i)\n",
    "            cols_to_drop.append((name, na, final_name))\n",
    "        dt = pd.DataFrame(cols_to_drop, columns = [\"Drop_name\", \"Number_Na\", \"Orignal_Name\"])\n",
    "        dt = dt.sort_values([\"Orignal_Name\", \"Number_Na\"], ascending = [True, True])\n",
    "        dt = dt.drop_duplicates(\"Orignal_Name\")\n",
    "        cols_to_keep = dt.Drop_name.values\n",
    "        data = data[cols_to_keep]\n",
    "        data = data.copy()\n",
    "        data.columns = dt.Orignal_Name.values.tolist()\n",
    "    else:\n",
    "        data = data\n",
    "\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ceo_year(data):\n",
    "    test1 = list()\n",
    "    counter = 0\n",
    "    for i in data[\"Name and Principal Position\"]:\n",
    "        if pd.isna(i) == True:\n",
    "            counter += 1\n",
    "        else:\n",
    "            test1.append(counter)\n",
    "            break\n",
    "    counter = 0\n",
    "    for i in data[\"Year\"]:\n",
    "        if pd.isna(i) == True:\n",
    "            counter += 1\n",
    "        else:\n",
    "            test1.append(counter)\n",
    "            break\n",
    "    check = test1[0] == test1[1]  \n",
    "    return(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_year(year):\n",
    "    year_extract = re.compile(\"\\d{4,4}$\")\n",
    "    year_extract_2 = re.compile(\"\\d{2,2}$\")\n",
    "    year_extract_3 = re.compile(\"TP|FY\")\n",
    "    if pd.isna(year) == False:\n",
    "        if year_extract.search(year) is not None:\n",
    "            year = year_extract.search(year).group(0).strip()\n",
    "        elif year_extract_2.search(year) is not None:\n",
    "            year = \"20\" + year_extract_2.search(year).group(0).strip()\n",
    "        elif year_extract_3.search(year) is not None:\n",
    "            year = re.sub(\"TP|FY\", \"\", year)\n",
    "    else:\n",
    "        year = year\n",
    "    return(year)\n",
    "\n",
    "def check_year(data):\n",
    "    year_test = re.compile(\"\\d{1,2}\\/\\d{1,2}\\/\\d{2,4}|TP|FY\")\n",
    "    year = data[pd.isna(data.Year) == False].Year\n",
    "    if any(year_test.search(str(x)) is not None for x in year) == True:\n",
    "        data[\"Old_Year\"] = data.Year\n",
    "        data[\"Year\"] = data.apply(lambda x: clean_year(x.Year), axis = 1)\n",
    "    else:\n",
    "        data = data\n",
    "    return(data)\n",
    "\n",
    "def clean_row(data):\n",
    "    data = data[data['Name and Principal Position'] != data['Year']]\n",
    "    return(data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_executives_names(data):\n",
    "    year_problem = re.compile(\"\\d\\d\\d\\d\\s+\\d\\d\\d\\d\\s+\\d\\d\\d\\d|\\d\\d\\d\\d\\s+\\d\\d\\d\\d\")\n",
    "    if check_ceo_year(data) == True:\n",
    "        data = check_year(data)\n",
    "        data = clean_row(data)\n",
    "        if any(year_problem.search(str(i)) is not None for i in data[pd.isna(data.Year) == False].Year) == True:\n",
    "            data = separate_rows(data)\n",
    "            executive_list = get_executives_name(data)\n",
    "            data = data[pd.isna(data.Year) == False]\n",
    "            dt = data.copy()\n",
    "            dt[\"Name\"] = executive_list[0]\n",
    "            dt[\"Role\"] = executive_list[1]   \n",
    "            dt[[\"Name\", \"Role\"]] = dt.apply(lambda x: fix_names_and_roles(x.Name, x.Role), axis = 1, result_type = \"expand\")  \n",
    "        else:\n",
    "            executive_list = get_executives_name(data)\n",
    "            data = data[pd.isna(data.Year) == False]\n",
    "            dt = data.copy()\n",
    "            dt[\"Name\"] = executive_list[0]\n",
    "            dt[\"Role\"] = executive_list[1]\n",
    "            if any(dt.Name == dt.Role) == True:\n",
    "                dt[[\"Name\", \"Role\"]] = dt.apply(lambda x: fix_names_and_roles(x.Name, x.Role), axis = 1, result_type = \"expand\")\n",
    "                \n",
    "    else:\n",
    "        dt = fix_names_not_aligned(data)\n",
    "        \n",
    "    dt = transform_names_and_roles(dt)   \n",
    "    dt[\"Name\"] = dt.apply(lambda x: re.sub(\"\\,\", \"\", x.Name), axis = 1)  \n",
    "    dt[\"Name\"] = dt.apply(lambda x: re.sub(\"\\([\\d\\w\\s]+\\)\", \"\", x.Name), axis = 1)  \n",
    "    return(dt)\n",
    "        \n",
    "        \n",
    "def get_executives_name(data):\n",
    "    name_executives = list()\n",
    "    function_list = list()\n",
    "    function = \"\"\n",
    "    counter = 0\n",
    "    for line in data.index:   \n",
    "        if str(float(data.Year.loc[line])) == str(data[pd.isna(data.Year) == False].Year.astype(float).max()):\n",
    "            name_input = data[\"Name and Principal Position\"].loc[line]\n",
    "            name_executives.append(name_input)\n",
    "            if counter == 0:\n",
    "                counter = 1\n",
    "            else:\n",
    "                function_list.append(function)\n",
    "                function = \"\"\n",
    "        else:\n",
    "            if pd.isna(data.Year.loc[line]) == False:\n",
    "                name_executives.append(name_input)\n",
    "                if pd.isna(data[\"Name and Principal Position\"].loc[line]) == False:\n",
    "                    if function.strip() != data[\"Name and Principal Position\"].loc[line]:\n",
    "                        function = function + \" \" + data[\"Name and Principal Position\"].loc[line]\n",
    "            else:\n",
    "                if pd.isna(data[\"Name and Principal Position\"].loc[line]) == False:\n",
    "                    if function.strip() != data[\"Name and Principal Position\"].loc[line]:\n",
    "                        function = function + \" \" + data[\"Name and Principal Position\"].loc[line]\n",
    "    function_list.append(function.strip())        \n",
    "    counter = 0\n",
    "    counter_func = 0\n",
    "    final_function = list()\n",
    "    for i in range(0,(len(name_executives))):\n",
    "        if counter == 0:\n",
    "            final_function.append(function_list[counter_func])\n",
    "            counter = 1\n",
    "        else:\n",
    "            if name_executives[i] == name_executives[(i-1)]:\n",
    "                final_function.append(function_list[counter_func])\n",
    "            else:\n",
    "                counter_func += 1\n",
    "                final_function.append(function_list[counter_func])    \n",
    "    return([name_executives, final_function])\n",
    "\n",
    "def separate_rows(data):\n",
    "    values_list = list()\n",
    "    colnames = list()\n",
    "    for col in data.columns:\n",
    "        if col != \"Name and Principal Position\":\n",
    "            new_df = pd.DataFrame(data[pd.isna(data[col]) == False][col].str.split('  ').tolist(), index=data[pd.isna(data[col]) == False][\"Name and Principal Position\"]).stack()\n",
    "            new_df.columns = [col]\n",
    "            values_list.append(new_df)\n",
    "            colnames.append(col)\n",
    "    df = pd.concat(values_list, axis = 1)\n",
    "    df.columns = colnames\n",
    "    df = df.reset_index([0, 'Name and Principal Position'])\n",
    "    df[\"Name\"] = df['Name and Principal Position']\n",
    "    df[\"Role\"] = df['Name and Principal Position']\n",
    "    return(df)\n",
    "\n",
    "def fix_names_not_aligned(data):\n",
    "    col_to_drop = data.columns[0]\n",
    "    data_executives = data[col_to_drop]\n",
    "    data_executives = data_executives.reset_index(drop = True)\n",
    "    data_info = data.drop(col_to_drop, axis = 1)\n",
    "    data_info = data_info.reset_index(drop = True)\n",
    "    year = max(data_info[\"Year\"][pd.isna(data_info.Year) == False])\n",
    "    new_name_counter = 0\n",
    "    name = re.compile(\"[A-zá]+\\s*[A-zá]\\.\\s*[A-zá]+\")\n",
    "    name_list_part1 = []\n",
    "    function_list = []\n",
    "    function = \"\"\n",
    "    for i in data_executives:\n",
    "        if new_name_counter == 0:\n",
    "            if pd.isna(i) == False:\n",
    "                name_list_part1.append(i)\n",
    "                new_name_counter = 1\n",
    "            else:\n",
    "                pass\n",
    "        elif new_name_counter == 1:\n",
    "            if pd.isna(i) == True:\n",
    "                function_list.append(function)\n",
    "                function = \"\"\n",
    "                new_name_counter = 0\n",
    "            elif name.search(i) is not None:\n",
    "                function_list.append(function)\n",
    "                name_list_part1.append(i)    \n",
    "                function = \"\"\n",
    "            else:\n",
    "                function = function + \" \" + i\n",
    "    if function not in function_list:\n",
    "        function_list.append(function)\n",
    "    name_list = []\n",
    "    function_final_list = []\n",
    "    counter = 0\n",
    "    for i in data_info[\"Year\"]:\n",
    "        if pd.isna(i) == False:\n",
    "            if i == year:\n",
    "                name_input = name_list_part1[counter]\n",
    "                function_input = function_list[counter]\n",
    "                name_list.append(name_input)\n",
    "                function_final_list.append(function_input)\n",
    "                if counter == (len(name_list_part1)-1):\n",
    "                    pass\n",
    "                else:\n",
    "                    counter += 1\n",
    "            else:\n",
    "                name_list.append(name_input)\n",
    "                function_final_list.append(function_input)\n",
    "        else:\n",
    "            pass\n",
    "    data_info = data_info.dropna(how = \"all\", axis = 0)\n",
    "    data_info = data_info.copy()\n",
    "    data_info[\"Name\"] = name_list\n",
    "    data_info[\"Role\"] = function_final_list\n",
    "    return(data_info)\n",
    "\n",
    "def transform_names_and_roles(data):\n",
    "    if any(data.Role == \"\") == True:\n",
    "        data[[\"Name\", \"Role\"]] = data.apply(lambda x: fix_names_and_roles(x.Name, x.Role), axis = 1, result_type = \"expand\")      \n",
    "    else:\n",
    "        data = data\n",
    "    return(data)\n",
    "\n",
    "def fix_names_and_roles(text_name, text_role):\n",
    "    name_1 = re.compile(\"^([A-zá\\-\\']+\\s*[A-Z]\\.\\s*[A-zá\\-\\']+|[A-Z]\\.\\s*[A-Z]\\.\\s*[A-z\\-\\']+|[A-Z]\\.\\s*[A-z\\-\\']+\\s*[A-z\\-\\']+|[A-Z]\\.\\s*[A-Z]\\.\\s*[A-z\\-\\']+[A-z\\-\\']+)\") \n",
    "    name_2 = re.compile(\"^([A-zá\\-\\']+\\s*[A-zá\\-\\']+)\")\n",
    "    if name_1.search(text_name) is not None:\n",
    "        name = name_1.search(text_name).group(1).strip()\n",
    "        role = re.sub(name, \"\", text_name)\n",
    "        role = re.sub(\"^\\,\", \"\", role)\n",
    "        role = role.strip()\n",
    "    elif name_2.search(text_name) is not None:\n",
    "        name = name_2.search(text_name).group(1).strip()\n",
    "        role = re.sub(name, \"\", text_name)\n",
    "        role = re.sub(name, \"\", text_name)\n",
    "        role = re.sub(\"^\\,\", \"\", role)\n",
    "        role = role.strip()\n",
    "    else:\n",
    "        name = text_name\n",
    "        role = text_role\n",
    "    return(name, role)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
